\documentclass[12pt]{article}

\usepackage{amsmath}
\usepackage{latexsym}
\usepackage{amstext}
\usepackage{array}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\title{Three-Dimensional Reconstruction Using the Encounter Probabilities}
\begin{document}
\maketitle

\section{Using inverted probabilities assuming a Rouse chain}
The procedure relies on the nearest neighbor connectivity. As with the previous method, we assume a Rouse polymer encounter probability formula, which drops with the distance between beads on the chain. The main observation here is that if we estimate the nearest neighbors encounter probability for each bead, we can construct the whole connectivity map of the polymer. It will later be left to show that the non-nearest neighbor encounter probability will serve as correction factors. (see also \ref{subsection_usingStructuralDistributionFunction})

\subsection{Smoothing the encounter signal}
To locate prominent features of the signal, we have to reduce noise accompanying the experimental data. There are several ways to smooth the encounter probability data. We list few plausible methods.
The smoothing is performed on the encounter frequency signal, before calculating the encounter probability. 

\subsubsection{Averaging}
Due to the structure of the encounter frequency matrix, we have to choose a proper smoothing kernel. To take into account the structure of the chain , smoothing is performed with the following kernel 


\subsubsection{Iterative Gaussian Smoothing}
We start by iteratively applying Gaussian kernel smoothing with increasing variance for several iterations. The number of iteration is determined by the numerical accuracy of the machine used, which produces noise after several iterations, depending on machine precision, which prevents us from applying the filter indefinitely. 

One possible numerical criterion for the presence of noise, is the change in the number of local maxima the signal has over all values of variance chosen in the smoothing procedure. We then choose the variance value that give rise to the minimal number of maximal points. 

\subsubsection{$\mu|\lambda$ smoothing}\label{subsubsection_muLambdaSmoothing} 

Taubin's $\mu|\lambda$ smoothing procedure \cite{taubin1995curve}works by sequentially applying Gaussian smoothing with alternate positive and negative scales factors $\lambda$ and $\mu$ respectively, for $N$ iterations. In fact, any type of weighting other than the Gaussian can be applied, with the condition that the weights sum to one, and that no vertex is included in its own neighborhood. 

At first we compute $v_i'$ from $v_i$ by adding to it an averaging of its neighborhood with a positive scale factor $\lambda$ 

\begin{equation*}
v_i' = v_i+\lambda\sum_{j\in i^*} (v_j-v_i)w_j
\end{equation*}
Then, we compute $v_i''$ from $v_i'$ using a negative scale factor $\mu<-\lambda<0$
\begin{equation*}
v_i'' = v_i'+\mu\sum_{j\in i^*} (v_j'-v_i')w_j
\end{equation*}
with $w_i$ the weighting mask, $i^*$ are the indices of the vertex $i$ neighborhood excluding itself. 

In practice, we perform this by two steps convolution over $N$ iterations with a $n_v\times n_v$ square convolution kernel $W$. The kernel is changed such that $W_{n_v/2,n_v/2} =0; \quad W_{ij}\leftarrow W_{ij}/\sum\sum W_{ij}$. For an input signal $V$, $V' = V+\lambda (V*W-V)$
and $V''= V'+\mu (V*W-V)$, over $N$ iterations. 

The variables $\mu,\lambda$ and $N$ are determined by solving the inequalities 
\begin{eqnarray*}
((\lambda-\mu)^2 /(-4\lambda\mu))^N &<& 1+\delta_{pB}\\
((1-\lambda k_{sB})(1-\mu k_{sB})^N &<& \delta_{sB}
\end{eqnarray*}
with the constraints:
\begin{equation*}
N>0,\quad 0<\lambda<-\mu,\quad \lambda<\frac{1}{k_{sB}},\quad \frac{1}{\lambda}+\frac{1}{\mu}=k_{pB}
\end{equation*} 
The filter's parameters are then $k_{sB}, k_{pB}$
We have to change the shape of the neighborhood for the convolution operations, to take into account the shape of the encounter frequency vs. distance matrix. 

\subsection{Smoothing by solving the inverse source problem}\label{subsection_SmoothingbyInverseHeat}
A fundamental solution to the 1D heat (diffusion) equation is the Gaussian
\begin{equation*}
G(x,t,y,\tau) =\frac{H(t-\tau)}{\sqrt{4\pi (t-\tau)}}\exp\left(-\frac{(x-y)^2}{4(t-\tau)}\right)
\end{equation*}
with $H$ the Heaviside step function. It has been shown that in the generalized connectivity Rouse model the distribution of the vectors between beads is a Gaussian. This motivates the use of a combination of the fundamental solution to smooth the HiC data. Given the noisy observations of the HiC we now wish to find a smooth solution to the heat equation that represents the data in the least-square sense. 

The HiC encounter signals are non monotonic which hold structural information about the underlying average polymer model. It is therefore not enough to only smooth the curves with the solution of the heat equation but also to allow flexibility of the solution to account for this non monotonicity. 

We therefore add a theoretical source term, $r(t)$, in the heat differential equation with which we will smooth the HiC signals. The problem now becomes to find the unknown function $r(t)$ given the noisy measurements $u(x,t)$, which is the inverse source problem.

We start by imagining that each one of the $N$ encounter probability signals represents the temperature of a metal bar, initially hotter than its surrounding. The distance between beads will be thought of as time in the heat equation, and we solve the problem for 3 space points, the middle one being our encounter signal, while the other two will be assigned the boundary conditions.
\subsubsection{formulation of the problem}
In this subsection I present the formulation given by \cite{hazanee2013inverse} to solve the inverse time-dependent source problem.
let $T>0$ be a fixed number and let $D_T=\{(x,t): 0<x<1,0<t\leq T \}$. consider the problem of finding the temperature $u(x,t)$ and the time-dependent heat source $r(t)$ which satisfy the heat conduction equation 
\begin{equation*}
u_t = u_{xx}+r(t)f(x,t),\quad (x,t)\in D_T
\end{equation*}
subject to the boundary conditions 
\begin{equation*}
u(0,t)=u(1,t), \quad u_x(0,t)+\alpha u(0,t)=0,\quad 0\leq t\leq T,
\end{equation*}
with $\alpha \neq 0$. The initial condition 
\begin{equation*}
u(x,0) = \phi (x),\quad 0\leq x\leq 1
\end{equation*}
and the additional condition 
\begin{equation*}
\int_0^1 u(x,t)dx = E(t),\quad 0\leq t\leq T
\end{equation*}


\subsection{The steps}\label{subsection_theSmoothingSteps}
For a HiC read of $N$ equally spaced segments. 
\begin{enumerate}
\item Obtain the encounter histogram of the HiC data.
\item Arrange the encounters as $3D$ matrix $E$, with $x$-axes as bead index $b=1,...,N$, $y$-axes as the distance $d=-(N-1),..(N-1)$ along the chain, and the $z$-axes the number of encounters $E(b,d)$. Arranging the HiC data from left to right, we distinguish between 'right' encounter matrix, $e_r(b,d)$ for $d>0$ and 'left' encounter matrix $e_l(b,-d)$ for $d<0$ such that $E=e_l(b,-d)\bigoplus e_r(b,d)$ which is  $N\times 2N$ matrix. 
\item Smooth $e_r(b,d)$ and $e_l(b,-d)$ using the procedure described in.
\item Normalize each row of the smoothed encounter histogram to get probabilities [Read about bias]
\end{enumerate}

\section{Reconstruction}


\section{Ideas and preliminary work}\label{section_ideasAndPreliminaryWork}
This section contains preliminary ideas and work. some sections are not edited and the information in them should be double-checked. 

\subsection{Using optimization methods}\label{subsection_optimizationMethods}
Given an encounter probability profile of the first bead in a Rouse chain of $N$ bead, we use the expected encounter model in the Rouse chain to give estimate on the 3D organization of the chain. Given the encounter profile $e$, we minimize the goal function of the form
\begin{eqnarray}
&& min\{f(d)\}\\
&& Ad\leq b\\
&& A_{eq}d=b_{eq}\\
&& l_b\leq d\leq u_b\\
&& c(d)\leq0\\
&& c_{eq}(d)=0
\end{eqnarray}
where $d$ is a vector of the distances of bead from bead 1, $f=\sum{d_j}$, $A\in M_{[N\times N]}$ is a matrix such that
\begin{equation}
A_{ii} =
\left\{
	\begin{array}{ll}
		 -1 & \mbox{if } \exists j \quad ;\|e_j-e_i\|\leq \epsilon \\
		 0 & \mbox{else} 
	\end{array}
\right.
\end{equation}
\begin{equation}
A_{ij} =
\left\{
	\begin{array}{ll}
		1/|J|  & \mbox{if } \|e_j-e_i\|\leq \epsilon \\
		0 & \mbox{else } 
	\end{array}
\right.
\end{equation}
for small $\epsilon$ of choice, and $J$ is the group of all indices $j$ such that $\|e_j-e_i\|\leq \epsilon$ for each $i$. The vector $b$ is the zero vector,  $b=0$, $l_b$ is the lower bound, set to be a vector of all ones, $u_b$ is the upper bound set to be a vector of all $N$. The non linear constraint 
\begin{equation}
c(d) = \sum_{i=1}^N \left(\frac{d_i^{-1.5}}{\sum_{i=1}^n d_i^{-1.5}}-e_i\right)^2
\end{equation}

\subsection{using delta functions}
For the sake of simplicity, we will look at the encounter probability from the view point of the first bead in a chain of $N$ beads.
To take into account the structure of the chain we take the probability density function of the vector between any two beads 
\begin{equation*}
Pr(R_1-R_j =r)=\left(\frac{3}{2\pi b^2 |1-j|}\right)^{3/2}\exp\left(-\frac{3r^2}{2|1-j|b^2}\right)
\end{equation*} 
and for the encounter $R_1=R_j$ we get 
\begin{equation*}
Pr(R_1=R_j)=\left(\frac{3}{2\pi b^2 |1-j|}\right)^{3/2}
\end{equation*}
Now assume that bead 1 and $j$ are connected by harmonic spring. Then, we make the additional changes to the encounter probability by introducing the random variable $\delta_{1j}$, which indicates whether bead 1 and $j$ are connected. 
The probability of encounter then becomes 
\begin{equation*}
Pr(R_1=R_j)=(1-\delta_{1j})\left(\frac{3}{2\pi b^2 |1-j|}\right)^{3/2}+\delta_{1j}\left(\frac{3}{2\pi b^2}\right)^{3/2}
\end{equation*}
or 

\begin{equation*}
Pr(R_1=R_j)=\left(\frac{3}{2\pi b^2}\right)^{3/2}\left(\frac{1-\delta_{1j}\left(1-|1-j|^{3/2}\right)}{|1-j|^{3/2}}\right)
\end{equation*}

Given a signal, $e_1(d)$ of HiC encounter probability for bead 1 with beads $d=2,..,N$, we want to estimate the random vector 
\begin{equation*}
\Delta = [\delta_{13},\delta_{14},...,\delta_{1N} ]
\end{equation*}
For this end, we calculate the maximum likelihood estimator for $\delta$

[Unfinished]

\subsection{Using structural distribution function}\label{subsection_usingStructuralDistributionFunction}
We first make the assumption that the encounter probability of beads within a loop is well approximated with that of a chain. From the point of view of bead 1. The probability to encounter bead $j$ is given by a superposition of all distances possible between the two beads times the probability of their encounter in the context of a chain. Let the distance along the chain between bead 1 and $j$ be $\beta_{1j}$. Then,
\begin{equation*}
Pr(R_1-R_j=0)=Pr(\beta_{1j}=1)f(1)+Pr(\beta_{1j}=2)f(2)+...+Pr(\beta_{1j}=j-1)f(j-1)
\end{equation*}
with the encounter probability function 
\begin{equation*}
f(d) = \left(\frac{3}{2\pi b^2 d}\right)^{3/2}
\end{equation*}
which can be written as $Pr(R_1-R_j=0)=\left<p_{1j},f\right> >0$, and indicates that the vectors $p$ and $f$ are independent, as expected. Note, that we sum up to the maximal possible distance along the chain between the beads, i.e $j-1$.
The properties of the function $p_{ij}$ will be discussed later. For now it is important to note that $p_{ij}$ signifies the probability of finding the bead $i$ and $j$ at a distance $\beta$ apart, where the distance is the taken along the graph, with no consideration to edge length. The function $p_{ij}$  holds the structural information for the chain, including all possible looping. Since we are concerned with the encounter of the first bead with all the rest, the function $p_{1j}$ will be written as $p$. 

If we treat $\beta$ as a continuous variable and set the first bead to be $R_0$, the maximal distance along the chain will becomes $j$. We further set $Pr(R_0-R_j=0)=Pr_{0j}$ 
\begin{equation*}
Pr_{0j}= \int_{0}^{j} p(\beta)f(\beta)d\beta= \left(\frac{3}{2\pi b^2}\right)^{3/2}\int_0^{j} \frac{p(\beta)}{\beta^{3/2}}d\beta
\end{equation*}
By integrating by parts we get 
\begin{equation}
Pr_{0j}=2\left(\frac{3}{2\pi b^2}\right)^{3/2}\left[1 -\frac{p(j)}{\sqrt{j}}+\int_0^{j}\frac{p^{(1)}(\beta)}{\sqrt{\beta}}d\beta  \right]
\end{equation}
here we assume that 
\begin{equation*}
\begin{cases}
p_{oj}(0)\rightarrow 1; & j\rightarrow +0\\
\frac{p_{oj}(\beta)}{\beta}\rightarrow 1; & \beta \rightarrow 0 
\end{cases}
\end{equation*}
 and $p^{(k)}$ signifies the $k^{th}$ derivative of $p(\delta)$
This is a reasonable assumption, since the probability that two adjacent beads are connected as the distance decreases should be 1. 

Continuing with the integration by parts we get 
\begin{equation*}
2\left(\frac{3}{2\pi b^2}\right)^{3/2}\left[1 -\frac{p(j)}{\sqrt{j}}+2[p^{(1)}(j)\sqrt{j}-\int_0^{j}\frac{p^{(2)}(\beta)}{\sqrt{\beta}}d\beta]\right]
\end{equation*}
And in the limit we have the formula:
\begin{equation*}
Pr_{0j}=2\left(\frac{3}{2\pi b^2}\right)^{3/2}\left[ 1+\sum_{k=1}^\infty (-1)^k p^{(k-1)}(j)\left(\sqrt{j}\right)^{2k-3} \frac{2^k}{\prod_{i=1}^k (2i-1)}\right]
\end{equation*} 

We can now state some assumptions regarding the function $p(\delta)$.
\begin{enumerate}
	\item $p(\delta)$ is infinitely differentiable
	\item $p(\delta)>0 \quad  \forall \delta >0$
	\item $p_{oj}(0)\rightarrow \delta;  j\rightarrow +0$
	\item $\frac{p_{oj}(\beta)}{\beta}\rightarrow 0; \beta \rightarrow 0$
\end{enumerate}


[NOTE, need to verify that the Gaussian fulfill these requirements]

Given that we observe $e_j$, the encounter probability between bead 1 and $j$, we want to estimate the probability that bead 1 and $j$ are neighbors.
We equate the encounter probability at 1 with this value 
\begin{equation*}
g_j = Pr_{1j}=2\left(\frac{3}{2\pi b^2}\right)^{3/2}\left[ 1+\sum_{k=1}^\infty (-1)^k p^{(k-1)}(j)\left(\sqrt{j}\right)^{2k-3} \frac{2^k}{\prod_{i=1}^k (2i-1)}\right] 
\end{equation*}
Truncating the series of $p$ up to the first term 
\begin{equation*}
g_j = 2\left(\frac{3}{2\pi b^2}\right)^{3/2}\left[1 -\frac{p(j)}{\sqrt{j}}\right]
\end{equation*}
In general, we can consider the parameter $j$ as a variable and obtain an equation for $p$ 
\begin{equation*}
p(j)= \left(1-\frac{g_j}{2(3/2\pi b^2)^{1.5}}\right)\sqrt{j}
\end{equation*}

We can see from this result that the probability that if $g_j$ is the neighbor of bead 1. we get $p(1)=0.5$


\bibliographystyle{plain}
\bibliography{3DStructureFromEncounterProbabilityBibliography} % the bibliography.bib file 
\end{document}